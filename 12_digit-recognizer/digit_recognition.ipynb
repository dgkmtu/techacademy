{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit_recognition.ipynb\n",
      "my_model2.h5\n",
      "my_model3.h5\n",
      "my_model4.h5\n",
      "my_model.h5\n",
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Lambda, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習データの取得\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (train.iloc[:,1:].values).astype('float32') # all pixcel values\n",
    "y_train = train.iloc[:, 0].values.astype('int32')\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [188.]\n",
      "  [255.]\n",
      "  [ 94.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [191.]\n",
      "  [250.]\n",
      "  [253.]\n",
      "  [ 93.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [123.]\n",
      "  [248.]\n",
      "  [253.]\n",
      "  [167.]\n",
      "  [ 10.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 80.]\n",
      "  [247.]\n",
      "  [253.]\n",
      "  [208.]\n",
      "  [ 13.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 29.]\n",
      "  [207.]\n",
      "  [253.]\n",
      "  [235.]\n",
      "  [ 77.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 54.]\n",
      "  [209.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [ 88.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 93.]\n",
      "  [254.]\n",
      "  [253.]\n",
      "  [238.]\n",
      "  [170.]\n",
      "  [ 17.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 23.]\n",
      "  [210.]\n",
      "  [254.]\n",
      "  [253.]\n",
      "  [159.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 16.]\n",
      "  [209.]\n",
      "  [253.]\n",
      "  [254.]\n",
      "  [240.]\n",
      "  [ 81.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 27.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [254.]\n",
      "  [ 13.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 20.]\n",
      "  [206.]\n",
      "  [254.]\n",
      "  [254.]\n",
      "  [198.]\n",
      "  [  7.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [168.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [196.]\n",
      "  [  7.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 20.]\n",
      "  [203.]\n",
      "  [253.]\n",
      "  [248.]\n",
      "  [ 76.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 22.]\n",
      "  [188.]\n",
      "  [253.]\n",
      "  [245.]\n",
      "  [ 93.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [103.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [191.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 89.]\n",
      "  [240.]\n",
      "  [253.]\n",
      "  [195.]\n",
      "  [ 25.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 15.]\n",
      "  [220.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [ 80.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 94.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [253.]\n",
      "  [ 94.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [ 89.]\n",
      "  [251.]\n",
      "  [253.]\n",
      "  [250.]\n",
      "  [131.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [214.]\n",
      "  [218.]\n",
      "  [ 95.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]\n",
      "\n",
      " [[  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]\n",
      "  [  0.]]]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x):\n",
    "    return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.pyenv/versions/3.7.5/lib/python3.7/site-packages/matplotlib/text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f0a685eec90>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a685ee8d0>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a685f4ed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a6857f390>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a6857f950>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a6857fed0>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a685d0510>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a685d0b50>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a685d0250>,\n",
       "  <matplotlib.axis.XTick at 0x7f0a685bc250>],\n",
       " <a list of 10 Text xticklabel objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dfZAkd33f8fd3Z59ud+budLe7s+jupL2TdjaWKEDKRcHGUJQliEQSqWwSlwQ4wYWtUIUcbFxJyRCDIRWXiV2OyxUBlgFDwJIsy4BVjkAkQQQqREQnnqwHZvZ0upPupJ3de57ZvX3+5o/pXo32dm5nd2emZ3o+r6opzfR0T3/34T7q/fW3f23ujoiItL6OqAsQEZHaUKCLiMSEAl1EJCYU6CIiMaFAFxGJCQW6iEhMKNBFRGJCgR5zZuZmNm1m/ynqWiR+zOzjwe+Xm1ln1PW0OwV6e3i9u38kfGFmbzCzJ81sJvjvG6r9IDMbMbPHgm1/amY3bWDbXWb21SAAjpnZuzaw7S+b2feC/X672u3Ktv8tM5sws/Nm9nkz69nAtu8K6p02s6+Z2a4NbHtj8H2aCb5vV25g26b/Obn7x4Brq/1sqS8Fepsxs27gb4EvA5cBXwT+NlhejfuBHwK7gY8AD5nZYJXb3gPMA2ng3cCnzazaMDgN/AnwB1Wuv8LM/glwN3AjcCVwAPh4ldteC/wZ8CuU6p4BPlXltgPAV4DfBXYBh4C/qnLbVv05SZTcXY8YPwAHri57/XbgBGBly14Abq7iszLAHJAqW/Zd4P1VbNtPKSQyZcu+BPzBBr+eXwO+vcFt7gN+v+z1jcBEldv+PnBf2eurgq8jVcW2dwLfW/U9uAD8gyq2bZmfEzAS/J511vN3WY/1HzpCbz/XAj/x4F9i4CdU92fztcARdy+ULftxldtmgEV3z21i2626NthX+X7TZrZ7o9u6+3MEgbeJbaeB56j+e91uPyfZIgV6+0kC51YtOwekGrDt+U1uu1Wr6w6fN+JrbsVto/o5yRYp0NtPEdi+atl2oLDGus2y7Vat3nf4vJm/5lbcViKmQG8/TwOvMzMrW/a6YHk12x4ws/KjtddXuW0O6DSz0U1su1VPB/sq32/e3U9tdFszOwD0UPp6NrptP6Ux+Gq/1+32c5KtinoQX4/6Prj4pGg3cAz4IKVguit43V3l5z0O/BHQC/wicBYYrHLbByh1X/QDb6L0p/y1VW6bCPb5fuA7wfOuKre9GZgArgF2At+iypOxlMaOzwNvDur+MvBAldsOBl/jO4N6Pwk8XuW2LfNzQidFm+YReQF61PkHvCrQg2XXAU9S6rj4AXBd2XsfBr5+ic8bAb4dbJsFbip7793A05fYdhfwNWCaUsfGu8reezNQvMS27w2+lvLHF8reLwJvvsT2HwLyQTj/BdBT9t7TwLsvse27gnqnKbUS7ip77+vAhy+x7U3AT4Pv17eBkbL3PgN85hLbtsTPSYHePA8LfiASU2Y2S6mF7U/d/Xejrkfixcw+Rul/lj1Av7svRVxSW1Ogi4jEhE6KiojEhAJdRCQmIpsdbWBgwEdGRqLavYhIS3ryySdPuvua8/JEFugjIyMcOnQoqt2LiLQkMztW6T0NuYiIxIQCXUQkJhToIiIxoUAXEYkJBbqISEysG+jB/RcnzeypCu+bmf2pmR02s5+Y2fW1L1NERNZTzRH6FyjNVlfJLcBo8LgT+PTWyxIRkY1aN9Dd/TuUbtBbyW3Af/OSx4GdZvaaWhUoreEbT73MxLnZqMsQaWu1GEPfA7xY9vp4sOwiZnanmR0ys0NTU1M12LU0g3MXFnj/l3/AZ797JOpSRNpaQ0+Kuvu97n7Q3Q8ODq555aq0oPF86e5k2bzuUiYSpVoE+glgX9nrvcEyaRNhkOcU6CKRqkWgPwz8q6Db5Y3AOXd/uQafKy0iN1EK8vz5Oc7OzEdcjUj7WndyLjO7H3grMGBmx4GPAV0A7v4Z4BHgHcBhYAb41XoVK80pmy+Q6DCWlp1cvsgN+3dFXZJIW1o30N39jnXed+ADNatIWs54vsjPXbWb746fJJcvKNBFIqIrRWVLThbnODU9z1vHhkj2dGocXSRCCnTZknD8fCydYjSdJDuhQBeJigJdtiTscMkMJxlLp8jlC+jG4yLRUKDLluTyBS7r62Iw2UMmneLMzAJTxbmoyxJpSwp02ZJcvkgmncLMGBtOAaWTpCLSeAp02TR3JzdRWAnyTLr0X42ji0RDgS6b9vK5WQpzi4wGQT6Q7Oayvi51uohERIEumxaeEB0LAt3MyKRTmtNFJCIKdNm0sGUxk06uLBsbTjGeL6rTRSQCCnTZtFy+SHp7Dzv7uleWZdIpinOLvKS50UUaToEum5bLF1ZOhIbCE6Q5nRgVaTgFumzK0rIzPnlxoGeGgk4XjaOLNJwCXTblxdMzzC4sr5wQDe3o6yK9vUdH6CIRUKDLpuRWLvlPXfReJp0iN6lAF2k0BbpsShjoo0PJi94bS5c6XZaW1eki0kgKdNmUbL7Ivl3b6O+5eEr9zHCKucVlXjg9E0FlIu1LgS6bkpsorJwAXU1TAIhEQ4EuG7awtMyRk8U1x8/hlWEYTQEg0lgKdNmwoyenWVjyizpcQv09nezbtU2BLtJgCnTZsJWbWlQIdGDlZhci0jgKdNmw3ESBRIdxYLC/4jqZdIojU9PMLy43sDKR9qZAlw3L5gtcubuP3q5ExXUy6RSLy87zJ6cbWJlIe1Ogy4bl8sWK4+ehlU4XDbuINIwCXTZkdmGJY6emLzl+DnBgsJ9EhzGuQBdpGAW6bMjhySLL/sqsipX0diUY2d2nXnSRBlKgy4bkquhwCY0Nq9NFpJEU6LIh2XyB7kQHI7v71l13dCjFsdMzXJhfakBlIqJAlw3JTRQ4MNhPZ2L9X52x4RTupWEaEak/BbpsSC5fXHf8PBQOy2jYRaQxFOhStcLsAifOXqhq/BxgZHcf3YkOBbpIgyjQpWrjwdBJtYHemejgqqGketFFGqSqQDezm80sa2aHzezuNd6/wsweM7MfmtlPzOwdtS9VohbeVm69i4rKZdJJ3Y5OpEHWDXQzSwD3ALcA1wB3mNk1q1b7D8CD7n4dcDvwqVoXKtHL5gts60qw97JtVW+TSad46dws52cX6liZiEB1R+g3AIfd/Yi7zwMPALetWseB7cHzHcBLtStRmsV4vkgmnaSjw6reJjyaH8+r00Wk3qoJ9D3Ai2WvjwfLyv0e8B4zOw48AvzGWh9kZnea2SEzOzQ1NbWJciVK2Xyh6vHzUNgRoxOjIvVXq5OidwBfcPe9wDuAL5nZRZ/t7ve6+0F3Pzg4OFijXUsjnJ6eZ6owt+FA37NzG33dCU0BINIA1QT6CWBf2eu9wbJy7wMeBHD3/wv0AgO1KFCaw8ol/1X2oIc6OozRoaSO0EUaoJpAfwIYNbP9ZtZN6aTnw6vWeQG4EcDMfoZSoGtMJUbCQN5Ih0soo7sXiTTEuoHu7ovAXcCjwLOUulmeNrNPmNmtwWq/Dfy6mf0YuB94r7t7vYqWxsvlC2zv7SS9vWfD244NpzhZnOdUca4OlYlIqLOaldz9EUonO8uXfbTs+TPAm2pbmjST3ETpkn+z6jtcQq9MAVDkZ5Mb/x+CiFRHV4rKutydbL7A6CaGW0CdLiKNokCXdU0W5jh3YWFT4+cAQ6ketvd2agoAkTpToMu6wpbDjbYshsysdLMLtS6K1JUCXdb1yl2Kkpv+jLDTRefKRepHgS7ryuULDCR72L2FE5pjwynOzy6SP69OF5F6UaDLurLBHC5bEQ7XaBxdpH4U6HJJy8vO+CbmcFltpXVR4+gidaNAl0s6cfYCM/NLVd92rpJd/d0MJHt0hC5SRwp0uaRXTohuLdABxoaTjCvQRepGgS6XlK1Bh0uo1OlSZHlZnS4i9aBAl0vKTRS4fEcvqd6uLX/WWDrFhYUljp+5UIPKRGQ1BbpcUjZf3PCUuZWMqtNFpK4U6FLR4tIyz00WN33J/2rhsI3mdBGpDwW6VHTs9AzzS8s1OSEKkOrtYs/ObQp0kTpRoEtFYc/4VlsWy2XSSd2OTqROFOhSUTZfwAyuGtx6h0soM5ziyNQ0C0vLNftMESlRoEtFuXyBK3f1sa07UbPPzAylmF9a5tip6Zp9poiUKNClouzE1i/5Xy0cvslOFGv6uSKiQJcK5haXOHpqpqbj5wBXDyUxU6eLSD0o0GVNR6amWVr2mh+h93YlGNndr0AXqQMFuqyplnO4rJZJJ3VxkUgdKNBlTdmJAp0dxv6B/pp/diad4ujJaWYXlmr+2SLtTIEua8rlixwY7Ke7s/a/Ipl0imUvDeuISO0o0GVNuRrc1KKS8ESrxtFFakuBLheZmV/khdMzNZvDZbWR3f10JUzj6CI1pkCXi4znSz3io3UK9O7ODg4MJHU7OpEaU6DLRcIj51r3oJcbVaeLSM0p0OUi4/kCPZ0dXLGrr277GEunOH7mAtNzi3Xbh0i7UaDLRbL5IqPpJIkOq9s+wptmjE9qCgCRWlGgy0VydZjDZbXwhKvG0UVqp6pAN7ObzSxrZofN7O4K6/yymT1jZk+b2X21LVMa5dzMAhPnZ+se6Pt29dHb1aFxdJEa6lxvBTNLAPcAbwOOA0+Y2cPu/kzZOqPA7wBvcvczZjZUr4KlvnKTwQnROgd6osO4eiipXnSRGqrmCP0G4LC7H3H3eeAB4LZV6/w6cI+7nwFw98nalimNsjKHSx07XEKZdEqBLlJD1QT6HuDFstfHg2XlMkDGzP6PmT1uZjev9UFmdqeZHTKzQ1NTU5urWOoqN1Eg2dPJ5Tt6676vsXSK/Pk5zs7M131fIu2gVidFO4FR4K3AHcCfm9nO1Su5+73uftDdDw4ODtZo11JL2XyBTDqJWf06XEKZlSkA1OkiUgvVBPoJYF/Z673BsnLHgYfdfcHdnwdylAJeWoi71+UuRZWE4/Q6MSpSG9UE+hPAqJntN7Nu4Hbg4VXrfI3S0TlmNkBpCOZIDeuUBjhZnOfMzELDAv01O3pJ9XSqdVGkRtYNdHdfBO4CHgWeBR5096fN7BNmdmuw2qPAKTN7BngM+HfufqpeRUt9jDfgkv9yZsZoWp0uIrWybtsigLs/AjyyatlHy5478KHgIS0qW8e7FFUyNpziG09N4O4NGbcXiTNdKSorcvkCl/V1MZDsbtg+M+kUZ2YWmCrONWyfInGlQJcV4QnRRh4pvzIFgDpdRLZKgS5AqcNlPF9s2Ph5KGxdVKeLyNYp0AWAl8/NUphbbOj4OcBAsodd/d0rJ2RFZPMU6AI05qYWlWR0swuRmlCgC/DKNLaZocYH+lg6RW6iQKlZSkQ2S4EuQOkIPb29hx19XQ3fd2Y4xfT8EifOXmj4vkXiRIEuQKllsdHj56GVThcNu4hsiQJdWFp2Dk8W6z4HeiWjaU3SJVILCnThxdMzzC4sN2QO9LXs2NbF8PZezekiskUKdInkkv/VMsMpdbqIbJECXVaOjEeHkpHVMJZOMj5ZZGlZnS4im6VAF7L5Avt2baO/p6q52uoik04xv7jMsVPTkdUg0uoU6FK65D/C4RZ4ZbhHJ0ZFNk+B3ubmF5d5bqoY6fg5wGi6NNyj1kWRzVOgt7mjp6ZZXPbIA72vu5MrdvXpxKjIFijQ21x2IvoOl1AmmAJARDZHgd7mcvkCiQ7jwGB/1KUwNpzk+ZPTzC8uR12KSEtSoLe5XL7AyO4+ersSUZdCJp1icdl5/qQ6XUQ2Q4He5nIR3NSiknDYR+PoIpujQG9jswtLHD01zWgEU+au5cBgP4kO0zi6yCYp0NvY4cki7tHc1GItPZ0J9g/06whdZJMU6G2smTpcQmPplHrRRTZJgd7GcpMFuhMdjOzui7qUFaPpJC+cnuHC/FLUpYi0HAV6G8tNFLhqKElnonl+DcbSKdxLw0EisjHN8y9ZGi6XL5JJRzfD4lrCOdk1ji6ycQr0NlWYXeDE2QtNNX4OcOWuPro7OzSOLrIJCvQ2NR4MaUQ9y+JqnYkOrh5MKtBFNkGB3qbCXu9maVksl0kn1YsusgkK9DaVzRfo606wZ+e2qEu5SGY4xUvnZjk/uxB1KSItRYHepnL5AqNDSTo6LOpSLhIOA41r2EVkQ6oKdDO72cyyZnbYzO6+xHrvNDM3s4O1K1HqITsR/U0tKlmZ02VCrYsiG7FuoJtZArgHuAW4BrjDzK5ZY70U8EHg+7UuUmrr9PQ8J4tzTTl+DrBn5zb6uxM6MSqyQdUcod8AHHb3I+4+DzwA3LbGev8R+CQwW8P6pA7CoGzWI/SODuNqTQEgsmHVBPoe4MWy18eDZSvM7Hpgn7v/90t9kJndaWaHzOzQ1NTUhouV2giDslmP0AHG0mpdFNmoLZ8UNbMO4I+B315vXXe/190PuvvBwcHBre5aNik7UWB7bydDqZ6oS6kok05xslgaGhKR6lQT6CeAfWWv9wbLQingtcC3zewo8EbgYZ0YbV65fIGx4RRmzdfhEgr/etBRukj1qgn0J4BRM9tvZt3A7cDD4Zvufs7dB9x9xN1HgMeBW939UF0qli1x92AOl+YdboHy1kV1uohUa91Ad/dF4C7gUeBZ4EF3f9rMPmFmt9a7QKmtycIc5y4sNPX4OcBgqocd27o0SZfIBnRWs5K7PwI8smrZRyus+9atlyX10ow3tViLmZVudqEpAESqpitF20yztyyWywwnyeYLuHvUpYi0BAV6m8lOFBhI9rCrvzvqUtY1lk5RmF1k4rwubRCphgK9zeQmi4wNN9dNLSoJ/4rI6cSoSFUU6G1kedkZzxdaYrgFygJd4+giVVGgt5ETZy8wM7/UMoF+WX83g6kedbqIVEmB3kZapcOl3JjmdBGpmgK9jWRXOlxaYwwdSv/zGc8XWV5Wp4vIehTobWQ8X2DPzm2keruiLqVqY8NJLiwscfzMhahLEWl6CvQ2ks0XW+roHGA0vNmFhl1E1qVAbxOLS8s8N9n8c7isNjpU+h+QxtFF1qdAbxNHT80wv7TccoGe6u1iz85tKyd0RaQyBXqbaIWbWlQyNqxOF5FqKNDbRC5fwAyuHmqtMXQodbocmZpmYWk56lJEmpoCvU3k8gVGdvfT25WIupQNy6STzC8tc+zUdNSliDQ1BXqbyE4UVk4wtppw3D87oTldRC5Fgd4GZheWOHpqpiXHz6E0TNRhal0UWY8CvQ0cmZpmadlbrsMl1NuVYGR3vybpElmHAr0NjE+2bodLKJNOkZtUoItcigK9DWQnCnQljJHd/VGXsmmZdJKjJ6eZXViKuhSRpqVAbwO5fIH9A/10d7bujzsznGLZ4bkpnRgVqaR1/4VL1bItdFOLSsZW7l6kYReRShToMTc9t8iLpy+sBGKrGhnopythal0UuQQFeswdniwFYKaFT4gCdCU6uGowybiO0EUqUqDHXNi73epH6FCaSle96CKVKdBjLjdRoKezg327+qIuZcvG0kmOn7lAcW4x6lJEmpICPeay+QKj6SSJDou6lC0LT+xq2EVkbQr0mMvFoMMlFF4YpU4XkbUp0GPs3MwC+fNzsRg/B9h3WR+9XR3k8up0EVmLAj3GwkvlW73DJdTRYYwO6WYXIpUo0GMsvG1bXIZcoPS16HZ0ImurKtDN7GYzy5rZYTO7e433P2Rmz5jZT8zsf5nZlbUvVTYqly+Q7Onk8h29UZdSM2PDSSYLc5yZno+6FJGms26gm1kCuAe4BbgGuMPMrlm12g+Bg+7+OuAh4D/XulDZuOxEgUw6iVnrd7iEMpoCQKSiao7QbwAOu/sRd58HHgBuK1/B3R9z95ng5ePA3tqWKRvl7uTyhZaeMnctK50ukzoxKrJaNYG+B3ix7PXxYFkl7wO+vtYbZnanmR0ys0NTU1PVVykbdrI4z5mZhViNnwMMb+8l1dOpm12IrKGmJ0XN7D3AQeAP13rf3e9194PufnBwcLCWu5ZVwiGJuAW6mZEZ1hQAImupJtBPAPvKXu8Nlr2Kmd0EfAS41d3nalOebFYcO1xCmXSpddHdoy5FpKlUE+hPAKNmtt/MuoHbgYfLVzCz64A/oxTmk7UvUzZqfLLArv5uBpLdUZdSc2PpJGdnFpgq6rhBpNy6ge7ui8BdwKPAs8CD7v60mX3CzG4NVvtDIAn8tZn9yMwervBx0iBx7HAJhRdK5TQ3usirdFazkrs/AjyyatlHy57fVOO6ZAtKHS5F3nn9pc5dt65wGCmbL/DzowMRVyPSPHSlaAy9dG6W4twiozEcPwcYSPawu79bnS4iqyjQYygMurj1oJfL6GYXIhdRoMfQSsviUHwDfWw4xbg6XUReRYEeQ9l8geHtvezo64q6lLrJpFNMzy9x4uyFqEsRaRoK9BjK5QuxmTK3kkw6CWhOF5FyCvSYWVp2xvNFMkPJqEupq/CEb1atiyIrFOgx88LpGeYWl2N/hL5jWxev2dGrI3SRMgr0mAkDLi63nbuUcAoAESlRoMdM2LI4mo73kAsEnS6TRZaW1ekiAgr02MnmC1yxq4++7qouAm5po0NJ5heXOXZqOupSRJqCAj1mcvnCSgdI3K3c7ELDLiKAAj1W5heXOTI1Hcspc9dy9VASM3W6iIQU6DFy9NQ0i8se60v+y/V1d3LFrj5ykzpCFwEFeqzE+aYWlWTSKU3SJRJQoMdILl8g0WEcGOyPupSGyaSTPH9ymrnFpahLEYmcAj1GshMFRnb30dOZiLqUhsmkUywuO8+fVKeLiAI9RnL5QtuMn4fCrzerYRcRBXpczC4scez0TFuNnwMcGEjS2WGM59XpIqJAj4nDk0Xc2+OS/3LdnR3sH+jXzS5EUKDHRnblkv/2CnTQnC4iIQV6TOTyBboTHYzs7ou6lIbLpFO8cHqGmfnFqEsRiZQCPSay+QJXDSXpTLTfj3RsOIl7adhJpJ2137/+mBrPFxlrkzlcVgtPBOd0YlTanAI9BgqzC5w4eyH2N7Wo5Mrd/XR3dmgcXdqeAj0GwiPTzFB7Bnqiw7h6MKledGl7CvQYWLlLUZseoUPpa9cRurQ7BXoMZCcK9HUn2LNzW9SlRCaTTvHyuVnOXViIuhSRyCjQY2B8ssBoOkVHh0VdSmTGhksnhA9rKl1pYwr0GMhOtG+HSyjsdNHNLqSdKdBb3KniHCeLc203h8tqe3Zuo787oXF0aWsK9Ba30uHS5oFuZoymU+p0kbZWVaCb2c1mljWzw2Z29xrv95jZXwXvf9/MRmpdqKxNHS6vGNOcLtLm1g10M0sA9wC3ANcAd5jZNatWex9wxt2vBv4L8MlaFypry+UL7NjWxVCqJ+pSIpcZTnFqep6TxbmoSxGJRGcV69wAHHb3IwBm9gBwG/BM2Tq3Ab8XPH8I+K9mZu7uNawVgAefeJE//+6RWn9sy3rp7AWuvXwHZu3b4RIKpw7+pU99j55OjSZK8/q3N47yz19/ec0/t5pA3wO8WPb6OPCPK63j7otmdg7YDZwsX8nM7gTuBLjiiis2VfDOvi5G27yjo9xoOskvXrc36jKawsGRy7j9H+3j/Kx60aW57djWVZfPrSbQa8bd7wXuBTh48OCmjt7ffu0wb792uKZ1STz0diX4g3e+LuoyRCJTzd+lJ4B9Za/3BsvWXMfMOoEdwKlaFCgiItWpJtCfAEbNbL+ZdQO3Aw+vWudh4F8Hz/8F8K16jJ+LiEhl6w65BGPidwGPAgng8+7+tJl9Ajjk7g8DnwO+ZGaHgdOUQl9ERBqoqjF0d38EeGTVso+WPZ8F/mVtSxMRkY1Qb5eISEwo0EVEYkKBLiISEwp0EZGYsKi6C81sCji2yc0HWHUVakRUx6upjuaqAVTHanGo40p3H1zrjcgCfSvM7JC7H1QdqqNZ62iGGlRH+9WhIRcRkZhQoIuIxESrBvq9URcQUB2vpjpe0Qw1gOpYLdZ1tOQYuoiIXKxVj9BFRGQVBbqISEy0XKCvd8PqBtXweTObNLOnoth/UMM+M3vMzJ4xs6fN7IMR1dFrZv/PzH4c1PHxKOooqydhZj80s7+LsIajZvb3ZvYjMzsUYR07zewhM/upmT1rZj8bQQ1jwfchfJw3s9+MoI7fCn4/nzKz+82st9E1BHV8MKjh6bp8H9y9ZR6Upu99DjgAdAM/Bq6JoI63ANcDT0X4vXgNcH3wPAXkIvpeGJAMnncB3wfeGOH35UPAfcDfRVjDUWAgqv2X1fFF4NeC593AzojrSQATlC6MaeR+9wDPA9uC1w8C743g638t8BTQR2mm2/8JXF3LfbTaEfrKDavdfR4Ib1jdUO7+HUrzvkfG3V929x8EzwvAs5R+cRtdh7t7MXjZFTwiOdNuZnuBfwp8Nor9NxMz20HpwONzAO4+7+5no62KG4Hn3H2zV4hvRSewLbijWh/wUgQ1/AzwfXefcfdF4H8Dv1TLHbRaoK91w+qGh1izMbMR4DpKR8dR7D9hZj8CJoH/4e6R1AH8CfDvgeWI9h9y4Jtm9mRwY/Qo7AemgL8IhqA+a2b9EdUSuh24v9E7dfcTwB8BLwAvA+fc/ZuNroPS0fmbzWy3mfUB7+DVt/fcslYLdFnFzJLA3wC/6e7no6jB3Zfc/Q2U7jd7g5m9ttE1mNk/Aybd/clG73sNP+/u1wO3AB8ws7dEUEMnpWHBT7v7dcA0EMk5J4Dg9pW3An8dwb4vo/SX/H7gcqDfzN7T6Drc/Vngk8A3gW8APwKWarmPVgv0am5Y3TbMrItSmP+lu38l6nqCP+kfA26OYPdvAm41s6OUhuJ+wcy+HEEd4REh7j4JfJXSUGGjHQeOl/219BClgI/KLcAP3D0fwb5vAp539yl3XwC+AvxcBHXg7p9z93/o7m8BzlA691UzrRbo1dywui2YmVEaH33W3f84wjoGzWxn8Hwb8Dbgp42uw91/x933uvsIpd+Lb7l7w4/CzKzfzFLhc+DtlP7Ubih3nwBeNLOxYNGNwDONrqPMHUQw3BJ4AXijmfUF/25upHTOqeHMbCj47xWUxs/vq+XnV3VP0WbhFW5Y3eg6zOx+4K3AgJkdBz7m7p9rcBlvAn4F+Ptg/Brgw9Bn5ZYAAACISURBVF66/2sjvQb4opklKB0gPOjukbUMNoE08NVSbtAJ3Ofu34iolt8A/jI4+DkC/GoURQT/Y3sb8G+i2L+7f9/MHgJ+ACwCPyS6KQD+xsx2AwvAB2p9olqX/ouIxESrDbmIiEgFCnQRkZhQoIuIxIQCXUQkJhToIiIxoUAXEYkJBbqISEz8f0RFX2LIXOJTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(y_train[9])\n",
    "plt.plot(y_train[9])\n",
    "plt.xticks(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 43\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization, Convolution2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape (None, 28, 28, 1)\n",
      "output shape (None, 10)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(standardize, input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"input shape\", model.input_shape)\n",
    "print(\"output shape\", model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.ImageDataGenerator at 0x7f0a6883ef10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "gen = image.ImageDataGenerator()\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = X_train\n",
    "y = y_train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches=gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 28, 28, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37800/37800 [==============================] - 563s 15ms/step - loss: 0.2400 - accuracy: 0.9342 - val_loss: 0.3299 - val_accuracy: 0.9098\n",
      "Epoch 2/5\n",
      "37800/37800 [==============================] - 562s 15ms/step - loss: 0.2159 - accuracy: 0.9417 - val_loss: 0.3519 - val_accuracy: 0.9091\n",
      "Epoch 3/5\n",
      "37800/37800 [==============================] - 562s 15ms/step - loss: 0.2099 - accuracy: 0.9436 - val_loss: 0.3768 - val_accuracy: 0.9026\n",
      "Epoch 4/5\n",
      "37800/37800 [==============================] - 563s 15ms/step - loss: 0.2068 - accuracy: 0.9448 - val_loss: 0.3780 - val_accuracy: 0.9105\n",
      "Epoch 5/5\n",
      "37800/37800 [==============================] - 564s 15ms/step - loss: 0.2047 - accuracy: 0.9455 - val_loss: 0.3951 - val_accuracy: 0.9036\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=5,\n",
    "                              validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# モデルの読込\n",
    "model2 = load_model('./my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fc51a3f187a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-91406e17b2cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_loss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss_values, 'bo')\n",
    "# b+ is for \"blue crosses\"\n",
    "plt.plot(epochs, val_loss_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo')\n",
    "plt.plot(epochs, val_acc_values, 'b+')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28, 28, 1)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = get_fc_model()\n",
    "fc.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 620s 16ms/step - loss: 0.1443 - accuracy: 0.9725 - val_loss: 0.5254 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "history = fc.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1,\n",
    "                           validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = load_model('./my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-955d759da1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ディープラーニングmodel3の予測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ディープラーニングmodel3の予測\n",
    "Y_pred = model3.predict_classes(X_test, verbose=0)\n",
    "\n",
    "print(classification_report(y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "def get_cnn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28, 28, 1)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model()\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "37800/37800 [==============================] - 3202s 85ms/step - loss: 0.0751 - accuracy: 0.9794 - val_loss: 0.1781 - val_accuracy: 0.9660\n",
      "Epoch 2/2\n",
      "37800/37800 [==============================] - 6612s 175ms/step - loss: 0.0829 - accuracy: 0.9808 - val_loss: 0.1805 - val_accuracy: 0.9671\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=2,\n",
    "                              validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./my_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = load_model('./my_model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.preprocessing.image.ImageDataGenerator at 0x7f0a6852a090>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37800/37800 [==============================] - 7838s 207ms/step - loss: 0.1085 - accuracy: 0.9683 - val_loss: 0.0946 - val_accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr=0.001 # lr:学習率\n",
    "history = model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1,\n",
    "                             validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./my_model4.h5')\n",
    "model5 = load_model('./my_model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "def get_bn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28, 28, 1)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "   32/37800 [..............................] - ETA: 37:13WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " The CPU implementation of FusedBatchNorm only supports NHWC tensor format for now.\n\t [[node sequential_3/batch_normalization/FusedBatchNormV3 (defined at /home/ec2-user/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_3260]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f8169f9d942e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                          \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                          verbose=1)],\n\u001b[0;32m---> 10\u001b[0;31m          validation_data=(X_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.5/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:  The CPU implementation of FusedBatchNorm only supports NHWC tensor format for now.\n\t [[node sequential_3/batch_normalization/FusedBatchNormV3 (defined at /home/ec2-user/.pyenv/versions/3.7.5/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_3260]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = get_bn_model()\n",
    "model.optimizer.lr=0.01\n",
    "#history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1,\n",
    "#                            validation_data=val_batches, validation_steps=val_batches.n)\n",
    "log = model.fit(X_train, y_train, epochs=1, batch_size=32, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                         min_delta=0, patience=100,\n",
    "                                                         verbose=1)],\n",
    "         validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
